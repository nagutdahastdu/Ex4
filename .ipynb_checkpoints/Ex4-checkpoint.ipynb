{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c838c530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from mdptoolbox import mdp\n",
    "from itertools import product\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843239b1",
   "metadata": {},
   "source": [
    "## Define states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70400dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = [\"white\", \"red\", \"blue\", \"empty\"]\n",
    "actions = [(\"store\",\"white\"), (\"store\",\"red\"), (\"store\",\"blue\"),\n",
    "           (\"restore\",\"white\"), (\"restore\",\"red\"), (\"restore\",\"blue\")]\n",
    "\n",
    "states = tuple(product(cells, cells, cells, cells, actions))\n",
    "states_dict = {s:i for i,s in enumerate(states)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e737ee",
   "metadata": {},
   "source": [
    "## Generate transition probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69667ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNextStates(state, action):\n",
    "    \n",
    "    next_states = []\n",
    "    valid = False\n",
    "    order = state[-1][0]\n",
    "    \n",
    "    if order == \"store\":\n",
    "        valid = state[action] == \"empty\"\n",
    "    else:\n",
    "        valid = state[action] == state[-1][-1]\n",
    "    \n",
    "    if valid:\n",
    "        if order == \"store\":\n",
    "            next_states = [i for i,s in enumerate(states) if (s[action] == state[-1][-1]) and\n",
    "                           ([x for j,x in enumerate(s) if j!=action][:-1] == [x for j,x in enumerate(state) if j!=action][:-1])]\n",
    "        else:\n",
    "            next_states = [i for i,s in enumerate(states) if (s[action] == \"empty\") and\n",
    "                           ([x for j,x in enumerate(s) if j!=action][:-1] == [x for j,x in enumerate(state) if j!=action][:-1])]   \n",
    "    else:\n",
    "        next_states = [i for i,s in enumerate(states) if (s[:-1] == state[:-1])]\n",
    "    \n",
    "    return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41bb1db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 1/6\n",
    "prob_end = 1 - (1/6)*5\n",
    "\n",
    "trans_prob_matrix = []\n",
    "\n",
    "for i in range(2*2):\n",
    "    \n",
    "    trans_prob = np.zeros((1536, 1536))\n",
    "    \n",
    "    for j in range(len(trans_prob)):\n",
    "        \n",
    "        next_states = getNextStates(states[j], i)\n",
    "          \n",
    "        for k,n in enumerate(next_states):\n",
    "            \n",
    "            if k == (len(next_states)-1):\n",
    "                trans_prob[j][n] = prob_end\n",
    "            else:\n",
    "                trans_prob[j][n] = prob\n",
    "\n",
    "    trans_prob_matrix.append(csr_matrix(trans_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f1d49",
   "metadata": {},
   "source": [
    "## Generate reward matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8cfe14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = {0: 10, 1: 5, 2: 5, 3: 0, \"fail\": -10}\n",
    "\n",
    "reward_matrix = []\n",
    "\n",
    "for state in states:\n",
    "    \n",
    "    reward = np.zeros(4, dtype=np.float16)\n",
    "    \n",
    "    order = str()\n",
    "    if state[-1][0] == \"store\":\n",
    "        order = \"store\"\n",
    "    else:\n",
    "        order = \"restore\"\n",
    "    \n",
    "    if order == \"store\":\n",
    "        for i,x in enumerate(reward):\n",
    "            if state[i]==\"empty\":\n",
    "                reward[i] = rewards[i]\n",
    "            else:\n",
    "                reward[i] = rewards[\"fail\"]\n",
    "    else:\n",
    "        for i,x in enumerate(reward):\n",
    "            if state[i] == state[-1][-1]:\n",
    "                reward[i] = rewards[i]\n",
    "            else:\n",
    "                reward[i] = rewards[\"fail\"]\n",
    "    reward_matrix.append(reward)\n",
    "    \n",
    "reward_matrix = np.array(reward_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d0e4a9",
   "metadata": {},
   "source": [
    "## Define and run MDPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a8a603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_it = 10000\n",
    "dscnt = 0.99999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dc518",
   "metadata": {},
   "source": [
    "### Policy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d10e75e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "919.6292378902435\n"
     ]
    }
   ],
   "source": [
    "mdp_pol_it = mdp.PolicyIteration(transitions=trans_prob_matrix, reward=reward_matrix, discount=dscnt, max_iter=max_it)\n",
    "mdp_pol_it.run()\n",
    "print(mdp_pol_it.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553aefc7",
   "metadata": {},
   "source": [
    "### Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efcd8c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020993947982788086\n"
     ]
    }
   ],
   "source": [
    "mdp_val_it = mdp.ValueIteration(transitions=trans_prob_matrix, reward=reward_matrix, discount=dscnt, max_iter=max_it)\n",
    "mdp_val_it.run()\n",
    "print(mdp_val_it.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373d606d",
   "metadata": {},
   "source": [
    "### Policy Iteration Modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1eb2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.259228467941284\n"
     ]
    }
   ],
   "source": [
    "mdp_pol_mod = mdp.PolicyIterationModified(transitions=trans_prob_matrix, \n",
    "                                          reward=reward_matrix, discount=dscnt, max_iter=max_it)\n",
    "mdp_pol_mod.run()\n",
    "print(mdp_pol_mod.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42d3c",
   "metadata": {},
   "source": [
    "### Relative Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba862bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006995677947998047\n"
     ]
    }
   ],
   "source": [
    "mdp_val_rel = mdp.RelativeValueIteration(transitions=trans_prob_matrix, reward=reward_matrix, max_iter=max_it)\n",
    "mdp_val_rel.run()\n",
    "print(mdp_val_rel.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2924f681",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a823894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.89526057243347\n"
     ]
    }
   ],
   "source": [
    "mdp_ql = mdp.QLearning(transitions=trans_prob_matrix, reward=reward_matrix, discount=dscnt, n_iter=10000)\n",
    "mdp_ql.run()\n",
    "print(mdp_ql.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9374a",
   "metadata": {},
   "source": [
    "## Generate greedy policy for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ede4f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy = []\n",
    "\n",
    "for state in states:\n",
    "    \n",
    "    failed = True\n",
    "    order = state[-1][0]\n",
    "\n",
    "    if order == \"store\":\n",
    "        for i in range(4):\n",
    "            if state[i] == \"empty\":\n",
    "                failed = False\n",
    "                greedy.append(i)\n",
    "                break\n",
    "    else: # order == \"restore\"\n",
    "        for i in range(4):\n",
    "            if state[i] == state[-1][-1]:\n",
    "                failed = False\n",
    "                greedy.append(i)\n",
    "                break\n",
    "    if failed:\n",
    "        greedy.append(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49eb56f",
   "metadata": {},
   "source": [
    "## Evaluate policy performance with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8356f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPolPerf(orders, policy):\n",
    "\n",
    "    state = [\"empty\",\"empty\",\n",
    "             \"empty\",\"empty\",\n",
    "             (\"action\",\"placeholder\")]\n",
    "    \n",
    "    distance = 0\n",
    "\n",
    "    for order in orders:\n",
    "        \n",
    "        state[-1] = order\n",
    "        cell = policy[states_dict[tuple(state)]]\n",
    "\n",
    "        if state[-1][0] == \"store\":\n",
    "            state[cell] = state[-1][-1]\n",
    "        else:\n",
    "            state[cell] = \"empty\"\n",
    "\n",
    "        if cell == 0:\n",
    "            distance += 2\n",
    "        elif cell == 1 or cell == 2:\n",
    "            distance += 4\n",
    "        else: #cell == 3\n",
    "            distance += 6\n",
    "\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9e89cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = []\n",
    "\n",
    "with open(\"warehouseorder2x2.txt\") as file:\n",
    "    rdr = csv.reader(file, delimiter='\\t')\n",
    "    for row in rdr:\n",
    "        orders.append((row[0], row[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e4951",
   "metadata": {},
   "source": [
    "### Performance per policy, based on the total number of cells the robot needs to traverse. Less is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92de7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MDP Policy Iteration : 208\n",
      "MDP Value Iteration  : 208\n",
      "MDP Pol.It. Modified : 208\n",
      "MDP Relative Val.It. : 208\n",
      "MDP Q-Learning       : 222\n",
      "Greedy               : 228\n"
     ]
    }
   ],
   "source": [
    "print(\"MDP Policy Iteration :\", getPolPerf(orders, mdp_pol_it.policy))\n",
    "print(\"MDP Value Iteration  :\", getPolPerf(orders, mdp_val_it.policy))\n",
    "print(\"MDP Pol.It. Modified :\", getPolPerf(orders, mdp_pol_mod.policy))\n",
    "print(\"MDP Relative Val.It. :\", getPolPerf(orders, mdp_val_rel.policy))\n",
    "print(\"MDP Q-Learning       :\", getPolPerf(orders, mdp_ql.policy))\n",
    "print(\"Greedy               :\", getPolPerf(orders, greedy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed044c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
